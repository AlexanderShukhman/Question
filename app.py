import streamlit as st
from transformers import pipeline

@st.cache_resource
def load_model():
   return pipeline("question-answering", model="AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru")

qa_model = load_model()
st.title("üìù –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–∫—Å—Ç—É")
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç", type=("txt", "md"))
question = st.text_input(
    "–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–∫—Å—Ç—É",
    placeholder="–ú–æ–π –≤–æ–ø—Ä–æ—Å?",
    disabled=not uploaded_file,
)

if uploaded_file and question:
    article = uploaded_file.read().decode()
    results = qa_model(question = question, context = article)

    st.write("–û—Ç–≤–µ—Ç")
    st.write(results["answer"])
